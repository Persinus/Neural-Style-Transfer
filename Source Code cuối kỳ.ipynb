{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAvaIc4NIm1-"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------- DEVICE ----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------------- UTILS ----------------------------\n",
        "@st.cache_data\n",
        "def pil_to_tensor(img: Image.Image, max_size=512, shape=None):\n",
        "    img = img.convert('RGB')\n",
        "    if shape:\n",
        "        img = img.resize(shape, Image.LANCZOS)\n",
        "    else:\n",
        "        size = min(max(img.size), max_size)\n",
        "        img.thumbnail((size, size), Image.LANCZOS)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "    ])\n",
        "    return transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "def load_uploaded_image(uploaded_file, max_size=512, shape=None):\n",
        "    \"\"\"Fix l·ªói UploadedFile kh√¥ng c√≥ .convert()\"\"\"\n",
        "    img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    return pil_to_tensor(img, max_size=max_size, shape=shape)\n",
        "\n",
        "def im_convert(tensor, max_display_size=400):\n",
        "    image = tensor.clone().detach().cpu().squeeze(0)\n",
        "    mean = torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
        "    std = torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
        "    image = image * std + mean\n",
        "    image = torch.clamp(image,0,1)\n",
        "    img = transforms.ToPILImage()(image)\n",
        "    img.thumbnail((max_display_size, max_display_size), Image.LANCZOS)\n",
        "    return img\n",
        "\n",
        "def pil_from_tensor(tensor):\n",
        "    return im_convert(tensor, max_display_size=1000)\n",
        "\n",
        "def gram_matrix(tensor):\n",
        "    b, c, h, w = tensor.size()\n",
        "    tensor = tensor.view(b, c, h*w)\n",
        "    return torch.bmm(tensor, tensor.transpose(1,2)) / (c*h*w)\n",
        "\n",
        "# ---------------------------- POST-PROCESSING ----------------------------\n",
        "def postprocess_pil(img: Image.Image, sharpen=0.0, tone=1.0, smooth=0.0, hdr=0.0):\n",
        "    if smooth > 0:\n",
        "        img = img.filter(ImageFilter.SMOOTH_MORE)\n",
        "    if sharpen > 0:\n",
        "        enhancer = ImageEnhance.Sharpness(img)\n",
        "        img = enhancer.enhance(1.0 + sharpen)\n",
        "    if tone != 1.0:\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        img = enhancer.enhance(tone)\n",
        "    if hdr > 0:\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        hdr_img = enhancer.enhance(1.5 + hdr)\n",
        "        img = Image.blend(img, hdr_img, min(0.6, hdr))\n",
        "    return img\n",
        "\n",
        "# ---------------------------- FEATURE EXTRACTOR ----------------------------\n",
        "class VGGFeatures(nn.Module):\n",
        "    def __init__(self, content_layers, style_layers):\n",
        "        super().__init__()\n",
        "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
        "        self.vgg = nn.Sequential(*list(vgg.children())[:29]).to(device).eval()\n",
        "        for p in self.vgg.parameters():\n",
        "            p.requires_grad = False\n",
        "        self.content_layers = content_layers\n",
        "        self.style_layers = style_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        content_features, style_features = {}, {}\n",
        "        for name, layer in self.vgg._modules.items():\n",
        "            x = layer(x)\n",
        "            if name in self.content_layers:\n",
        "                content_features[name] = x\n",
        "            if name in self.style_layers:\n",
        "                style_features[name] = x\n",
        "        return content_features, style_features\n",
        "\n",
        "# ---------------------------- STREAMLIT APP ----------------------------\n",
        "st.set_page_config(page_title=\"üé® Neural Style Transfer\", layout=\"wide\")\n",
        "st.title(\"üé® Neural Style Transfer - Chuy·ªÉn Phong C√°ch Ngh·ªá Thu·∫≠t\")\n",
        "\n",
        "# ---------------------------- Session state ----------------------------\n",
        "if 'loss_table' not in st.session_state:\n",
        "    st.session_state.loss_table = pd.DataFrame(columns=[\"Step\",\"Total Loss\",\"Content Loss\",\"Style Loss\",\"Optimizer\"])\n",
        "# per-optimizer summary tables (m·ªói h√†ng = m·ªëc 100 step trung b√¨nh / ho·∫∑c m·ªëc cu·ªëi)\n",
        "if 'loss_table_lbfgs' not in st.session_state:\n",
        "    st.session_state.loss_table_lbfgs = pd.DataFrame(columns=[\"Step\",\"Avg Total\",\"Avg Content\",\"Avg Style\"])\n",
        "if 'loss_table_adam' not in st.session_state:\n",
        "    st.session_state.loss_table_adam = pd.DataFrame(columns=[\"Step\",\"Avg Total\",\"Avg Content\",\"Avg Style\"])\n",
        "if \"target_img\" not in st.session_state: st.session_state.target_img = None\n",
        "if \"adam_target_img\" not in st.session_state: st.session_state.adam_target_img = None\n",
        "if \"timings\" not in st.session_state: st.session_state.timings = {}\n",
        "\n",
        "# ---------------------------- Tabs ----------------------------\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\"Upload & Settings\", \"Training Progress\", \"Result & Download\", \"So s√°nh Optimizers\"])\n",
        "\n",
        "# ---------------------------- Sidebar: Upload & Settings ----------------------------\n",
        "with st.sidebar:\n",
        "    st.header(\"üìÇ Upload ·∫¢nh\")\n",
        "    content_file = st.file_uploader(\"·∫¢nh N·ªôi Dung\", type=[\"jpg\",\"png\"])\n",
        "    style_files = st.file_uploader(\"·∫¢nh Phong C√°ch (nhi·ªÅu)\", type=[\"jpg\",\"png\"], accept_multiple_files=True)\n",
        "\n",
        "    st.header(\"‚öôÔ∏è Tham s·ªë\")\n",
        "    # th√™m 500\n",
        "    steps_choice = st.selectbox(\"Steps\", [100,200,300,400,500], index=1)\n",
        "    downsample = st.slider(\"K√≠ch th∆∞·ªõc t·ªëi ƒëa\", 256, 1024, 512, step=64)\n",
        "    alpha = st.slider(\"Œ± (Content)\", 0.1, 10.0, 1.0, 0.1)\n",
        "    beta = st.slider(\"Œ≤ (Style)\", 1e3, 1e5, 1e4, step=1e3, format=\"%.0f\")\n",
        "\n",
        "    st.header(\"Optimizers\")\n",
        "    run_lbfgs = st.checkbox(\"D√πng L-BFGS\", True)\n",
        "    run_adam = st.checkbox(\"D√πng Adam\", True)\n",
        "    adam_lr = st.slider(\"Adam LR\", 1e-3, 1e-1, 1e-2, format=\"%.4f\")\n",
        "\n",
        "    st.header(\"H·∫≠u x·ª≠ l√Ω\")\n",
        "    sharpen = st.slider(\"Sharpen\", 0.0, 2.0, 0.0)\n",
        "    tone = st.slider(\"Tone\", 0.5, 2.0, 1.0)\n",
        "    smooth = st.slider(\"Smooth\", 0.0, 2.0, 0.0)\n",
        "    hdr = st.slider(\"HDR\", 0.0, 1.0, 0.0)\n",
        "\n",
        "    start_button = st.button(\"üöÄ Start\")\n",
        "    reset_button = st.button(\"‚ôª Reset\")\n",
        "\n",
        "    # N√∫t xem gi·∫£i th√≠ch tham s·ªë ‚Äî d√πng expander ƒë·ªÉ kh√¥ng l√†m r·ªëi giao di·ªán\n",
        "    with st.expander(\"üîé Gi·∫£i th√≠ch c√°c tham s·ªë (b·∫•m ƒë·ªÉ m·ªü)\"):\n",
        "        st.markdown(\"\"\"\n",
        "        - **Œ± (Content)**: h·ªá s·ªë cho content loss. **TƒÉng** n·∫øu mu·ªën gi·ªØ nhi·ªÅu k·∫øt c·∫•u/n·ªôi dung g·ªëc h∆°n; **gi·∫£m** n·∫øu mu·ªën ·∫£nh h∆∞·ªüng c·ªßa phong c√°ch m·∫°nh h∆°n.\n",
        "        - **Œ≤ (Style)**: h·ªá s·ªë cho style loss. **TƒÉng** ƒë·ªÉ √°p phong c√°ch r√µ r·ªát h∆°n; **gi·∫£m** n·∫øu phong c√°ch qu√° √°p ƒë·∫£o.\n",
        "        - **Steps**: s·ªë v√≤ng t·ªëi ∆∞u. Nhi·ªÅu b∆∞·ªõc ‚Üí ·∫£nh m∆∞·ª£t v√† ·ªïn ƒë·ªãnh h∆°n nh∆∞ng t·ªën th·ªùi gian.\n",
        "        - **Adam LR**: learning rate cho Adam. N·∫øu loss kh√¥ng gi·∫£m ‚Üí th·ª≠ gi·∫£m LR; n·∫øu qu√° ch·∫≠m ‚Üí c√≥ th·ªÉ tƒÉng nh·∫π (c·∫©n tr·ªçng).\n",
        "        - **Sharpen / Tone / Smooth / HDR**: h·∫≠u x·ª≠ l√Ω ·∫£nh cu·ªëi c√πng ‚Äî ƒëi·ªÅu ch·ªânh tr·ª±c quan sau khi train.\n",
        "        \"\"\")\n",
        "        st.markdown(\"**G·ª£i √Ω**: n·∫øu mu·ªën nhi·ªÅu chi ti·∫øt phong c√°ch nh·ªè, tƒÉng beta v√†/ho·∫∑c tƒÉng steps; n·∫øu mu·ªën b·∫£o t·ªìn b·ªë c·ª•c, tƒÉng alpha.\")\n",
        "\n",
        "# ---------------------------- RESET ----------------------------\n",
        "if reset_button:\n",
        "    st.session_state.loss_table = pd.DataFrame(columns=[\"Step\",\"Total Loss\",\"Content Loss\",\"Style Loss\",\"Optimizer\"])\n",
        "    st.session_state.loss_table_lbfgs = pd.DataFrame(columns=[\"Step\",\"Avg Total\",\"Avg Content\",\"Avg Style\"])\n",
        "    st.session_state.loss_table_adam = pd.DataFrame(columns=[\"Step\",\"Avg Total\",\"Avg Content\",\"Avg Style\"])\n",
        "    st.session_state.target_img = None\n",
        "    st.session_state.adam_target_img = None\n",
        "    st.session_state.timings = {}\n",
        "    st.experimental_rerun()\n",
        "\n",
        "# ---------------------------- Tab 1 ----------------------------\n",
        "with tab1:\n",
        "    st.subheader(\"Upload & Preview\")\n",
        "    cols = st.columns(2)\n",
        "    # Hi·ªÉn th·ªã content v√† blended style c√πng h√†ng\n",
        "    if content_file is not None:\n",
        "        try:\n",
        "            content_preview = Image.open(content_file).convert(\"RGB\")\n",
        "            cols[0].image(content_preview, caption=\"Content\", use_column_width=True)\n",
        "        except Exception:\n",
        "            cols[0].write(\"Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh n·ªôi dung.\")\n",
        "    else:\n",
        "        cols[0].info(\"Ch∆∞a upload ·∫£nh n·ªôi dung\")\n",
        "\n",
        "    if style_files and len(style_files) > 0:\n",
        "        try:\n",
        "            # Blend thumbnails for preview\n",
        "            thumbs = [Image.open(f).convert(\"RGB\").resize((256,256), Image.LANCZOS) for f in style_files]\n",
        "            # t·∫°o 1 h√†ng ·∫£nh phong c√°ch nh·ªè\n",
        "            row_w = sum(t.width for t in thumbs)\n",
        "            blend_canvas = Image.new(\"RGB\", (256*len(thumbs), 256))\n",
        "            for i, t in enumerate(thumbs):\n",
        "                blend_canvas.paste(t, (i*256,0))\n",
        "            cols[1].image(blend_canvas, caption=\"Blended Style (preview)\", use_column_width=True)\n",
        "        except Exception:\n",
        "            cols[1].write(\"Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh phong c√°ch.\")\n",
        "    else:\n",
        "        cols[1].info(\"Ch∆∞a upload ·∫£nh phong c√°ch\")\n",
        "\n",
        "# ---------------------------- START NST ----------------------------\n",
        "if start_button:\n",
        "    if content_file is None or len(style_files) == 0:\n",
        "        st.error(\"B·∫°n ph·∫£i ch·ªçn ·∫£nh n·ªôi dung v√† √≠t nh·∫•t 1 ·∫£nh phong c√°ch!\")\n",
        "        st.stop()\n",
        "\n",
        "    content = load_uploaded_image(content_file, max_size=downsample)\n",
        "\n",
        "    # FIX L·ªñI T·∫†I ƒê√ÇY ‚Äî convert UploadedFile ‚Üí PIL.Image ƒë√∫ng chu·∫©n\n",
        "    style_tensors = [\n",
        "        load_uploaded_image(f, max_size=downsample, shape=tuple(content.shape[-2:][::-1]))\n",
        "        for f in style_files\n",
        "    ]\n",
        "    style = torch.mean(torch.stack(style_tensors), dim=0)\n",
        "\n",
        "    # show small previews again inside tab1 (kept UI behavior)\n",
        "    with tab1:\n",
        "        c1, c2 = st.columns(2)\n",
        "        c1.image(im_convert(content), caption=\"Content\")\n",
        "        c2.image(im_convert(style), caption=\"Blended Style\")\n",
        "\n",
        "    content_layers = [\"21\"]\n",
        "    style_layers = [\"0\",\"5\",\"10\",\"19\",\"28\"]\n",
        "    extractor = VGGFeatures(content_layers, style_layers)\n",
        "\n",
        "    content_feat, _ = extractor(content)\n",
        "    style_feat = extractor(style)[1]\n",
        "    style_grams = {l: gram_matrix(style_feat[l]) for l in style_layers}\n",
        "\n",
        "    # Prepare progress UI placeholders in tab2\n",
        "    with tab2:\n",
        "        st.subheader(\"ƒêang ch·∫°y t·ªëi ∆∞u‚Ä¶\")\n",
        "        # Two columns: LBFGS / Adam progress + tables\n",
        "        pcols = st.columns(2)\n",
        "        lbfgs_status = pcols[0].empty()\n",
        "        lbfgs_progress = pcols[0].progress(0)\n",
        "        adam_status = pcols[1].empty()\n",
        "        adam_progress = pcols[1].progress(0)\n",
        "\n",
        "        # Two dataframes to display (per-optimizer summary m·ªëc 100)\n",
        "        tcols = st.columns(2)\n",
        "        lbfgs_table_placeholder = tcols[0].empty()\n",
        "        adam_table_placeholder = tcols[1].empty()\n",
        "\n",
        "    # ---------------------------- OPTIMIZATION ----------------------------\n",
        "    def run_lbfgs(target, steps, progress_bar=None, status_placeholder=None, table_placeholder=None):\n",
        "        optimizer = torch.optim.LBFGS([target], max_iter=1)\n",
        "        c_losses, s_losses, totals = [], [], []\n",
        "        start = time.time()\n",
        "        interval_size = 100\n",
        "        last_interval_index = 0\n",
        "        for step in range(steps):\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                t_content, t_style = extractor(target)\n",
        "                c_loss = torch.mean((t_content[\"21\"] - content_feat[\"21\"])**2)\n",
        "                s_loss = sum(torch.mean((gram_matrix(t_style[l]) - style_grams[l])**2) for l in style_layers)\n",
        "                loss = alpha*c_loss + beta*s_loss\n",
        "                loss.backward()\n",
        "                c_losses.append(c_loss.item()); s_losses.append(s_loss.item()); totals.append(loss.item())\n",
        "                return loss\n",
        "            optimizer.step(closure)\n",
        "\n",
        "            # update progress UI\n",
        "            if progress_bar is not None:\n",
        "                pct = int(((step+1)/steps)*100)\n",
        "                progress_bar.progress(pct)\n",
        "            if status_placeholder is not None:\n",
        "                status_placeholder.info(f\"L-BFGS: step {step+1}/{steps}  ‚Äî loss {totals[-1]:.4f}\")\n",
        "\n",
        "            # every interval_size steps or final step -> add summary row\n",
        "            if ((step+1) % interval_size == 0) or (step+1 == steps):\n",
        "                seg_tot = totals[last_interval_index:step+1]\n",
        "                seg_c = c_losses[last_interval_index:step+1]\n",
        "                seg_s = s_losses[last_interval_index:step+1]\n",
        "                if len(seg_tot) > 0:\n",
        "                    avg_tot = float(np.mean(seg_tot))\n",
        "                    avg_c = float(np.mean(seg_c))\n",
        "                    avg_s = float(np.mean(seg_s))\n",
        "                    mstep = step+1\n",
        "                    st.session_state.loss_table_lbfgs.loc[len(st.session_state.loss_table_lbfgs)] = [mstep, avg_tot, avg_c, avg_s]\n",
        "                    # update table display\n",
        "                    if table_placeholder is not None:\n",
        "                        table_placeholder.dataframe(st.session_state.loss_table_lbfgs, use_container_width=True)\n",
        "                last_interval_index = step+1\n",
        "\n",
        "        return target.detach(), c_losses, s_losses, totals, time.time() - start\n",
        "\n",
        "    def run_adam(target, steps, lr, progress_bar=None, status_placeholder=None, table_placeholder=None):\n",
        "        optimizer = torch.optim.Adam([target], lr=lr)\n",
        "        c_losses, s_losses, totals = [], [], []\n",
        "        start = time.time()\n",
        "        interval_size = 100\n",
        "        last_interval_index = 0\n",
        "        for step in range(steps):\n",
        "            optimizer.zero_grad()\n",
        "            t_content, t_style = extractor(target)\n",
        "            c_loss = torch.mean((t_content[\"21\"] - content_feat[\"21\"])**2)\n",
        "            s_loss = sum(torch.mean((gram_matrix(t_style[l]) - style_grams[l])**2) for l in style_layers)\n",
        "            loss = alpha*c_loss + beta*s_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            c_losses.append(c_loss.item()); s_losses.append(s_loss.item()); totals.append(loss.item())\n",
        "\n",
        "            # update progress UI\n",
        "            if progress_bar is not None:\n",
        "                pct = int(((step+1)/steps)*100)\n",
        "                progress_bar.progress(pct)\n",
        "            if status_placeholder is not None:\n",
        "                status_placeholder.info(f\"Adam: step {step+1}/{steps}  ‚Äî loss {totals[-1]:.4f}\")\n",
        "\n",
        "            # every interval_size steps or final step -> add summary row\n",
        "            if ((step+1) % interval_size == 0) or (step+1 == steps):\n",
        "                seg_tot = totals[last_interval_index:step+1]\n",
        "                seg_c = c_losses[last_interval_index:step+1]\n",
        "                seg_s = s_losses[last_interval_index:step+1]\n",
        "                if len(seg_tot) > 0:\n",
        "                    avg_tot = float(np.mean(seg_tot))\n",
        "                    avg_c = float(np.mean(seg_c))\n",
        "                    avg_s = float(np.mean(seg_s))\n",
        "                    mstep = step+1\n",
        "                    st.session_state.loss_table_adam.loc[len(st.session_state.loss_table_adam)] = [mstep, avg_tot, avg_c, avg_s]\n",
        "                    if table_placeholder is not None:\n",
        "                        table_placeholder.dataframe(st.session_state.loss_table_adam, use_container_width=True)\n",
        "                last_interval_index = step+1\n",
        "\n",
        "        return target.detach(), c_losses, s_losses, totals, time.time() - start\n",
        "\n",
        "    # RUN BOTH (v·∫´n gi·ªØ logic c≈© cho training)\n",
        "    with tab2:\n",
        "        # reset global combined table for plotting later (optional)\n",
        "        st.session_state.loss_table = pd.DataFrame(columns=[\"Step\",\"Total Loss\",\"Content Loss\",\"Style Loss\",\"Optimizer\"])\n",
        "\n",
        "        if run_lbfgs:\n",
        "            lbfgs_status.info(\"üîµ L-BFGS started\")\n",
        "            t_lbfgs, c_l, s_l, tot_l, elapsed = run_lbfgs(content.clone().requires_grad_(True), steps_choice,\n",
        "                                                         progress_bar=lbfgs_progress,\n",
        "                                                         status_placeholder=lbfgs_status,\n",
        "                                                         table_placeholder=lbfgs_table_placeholder)\n",
        "            st.session_state.target_img = t_lbfgs\n",
        "            st.session_state.timings[\"LBFGS\"] = elapsed\n",
        "            # append per-step to combined table (kept for plotting / record)\n",
        "            for i in range(len(tot_l)):\n",
        "                st.session_state.loss_table.loc[len(st.session_state.loss_table)] = [i+1,tot_l[i],c_l[i],s_l[i],\"LBFGS\"]\n",
        "            lbfgs_status.success(\"üîµ L-BFGS done\")\n",
        "\n",
        "        if run_adam:\n",
        "            adam_status.info(\"üü† Adam started\")\n",
        "            t_adam, c_a, s_a, tot_a, elapsed = run_adam(content.clone().requires_grad_(True), steps_choice, adam_lr,\n",
        "                                                       progress_bar=adam_progress,\n",
        "                                                       status_placeholder=adam_status,\n",
        "                                                       table_placeholder=adam_table_placeholder)\n",
        "            st.session_state.adam_target_img = t_adam\n",
        "            st.session_state.timings[\"Adam\"] = elapsed\n",
        "            for i in range(len(tot_a)):\n",
        "                st.session_state.loss_table.loc[len(st.session_state.loss_table)] = [i+1,tot_a[i],c_a[i],s_a[i],\"Adam\"]\n",
        "            adam_status.success(\"üü† Adam done\")\n",
        "\n",
        "        st.success(\"üéâ Ho√†n t·∫•t!\")\n",
        "\n",
        "# ---------------------------- Tab 3: RESULT & DOWNLOAD ----------------------------\n",
        "with tab3:\n",
        "    st.subheader(\"·∫¢nh k·∫øt qu·∫£\")\n",
        "    cols = st.columns(2)\n",
        "    if st.session_state.target_img is not None:\n",
        "        img = postprocess_pil(pil_from_tensor(st.session_state.target_img), sharpen, tone, smooth, hdr)\n",
        "        cols[0].image(img, caption=\"L-BFGS\")\n",
        "        # download button\n",
        "        buf = BytesIO()\n",
        "        img.save(buf, format=\"PNG\")\n",
        "        buf.seek(0)\n",
        "        cols[0].download_button(\"T·∫£i L-BFGS\", data=buf, file_name=\"result_lbfgs.png\", mime=\"image/png\")\n",
        "    else:\n",
        "        cols[0].info(\"Ch∆∞a c√≥ k·∫øt qu·∫£ L-BFGS\")\n",
        "\n",
        "    if st.session_state.adam_target_img is not None:\n",
        "        img2 = postprocess_pil(pil_from_tensor(st.session_state.adam_target_img), sharpen, tone, smooth, hdr)\n",
        "        cols[1].image(img2, caption=\"Adam\")\n",
        "        buf2 = BytesIO()\n",
        "        img2.save(buf2, format=\"PNG\")\n",
        "        buf2.seek(0)\n",
        "        cols[1].download_button(\"T·∫£i Adam\", data=buf2, file_name=\"result_adam.png\", mime=\"image/png\")\n",
        "    else:\n",
        "        cols[1].info(\"Ch∆∞a c√≥ k·∫øt qu·∫£ Adam\")\n",
        "\n",
        "    if not st.session_state.loss_table.empty:\n",
        "        st.subheader(\"Bi·ªÉu ƒë·ªì Loss (Total)\")\n",
        "        fig, ax = plt.subplots()\n",
        "        for opt in st.session_state.loss_table[\"Optimizer\"].unique():\n",
        "            df = st.session_state.loss_table[st.session_state.loss_table[\"Optimizer\"]==opt]\n",
        "            ax.plot(df[\"Total Loss\"].values, label=opt)\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    # show the per-100-step summary tables (side-by-side)\n",
        "    st.subheader(\"B·∫£ng t√≥m t·∫Øt m·ªói 100 step (ho·∫∑c m·ªëc cu·ªëi)\")\n",
        "    scols = st.columns(2)\n",
        "    scols[0].markdown(\"**L-BFGS**\")\n",
        "    scols[1].markdown(\"**Adam**\")\n",
        "    scols[0].dataframe(st.session_state.loss_table_lbfgs if not st.session_state.loss_table_lbfgs.empty else pd.DataFrame({\"Info\":[\"Ch∆∞a c√≥ d·ªØ li·ªáu\"]}))\n",
        "    scols[1].dataframe(st.session_state.loss_table_adam if not st.session_state.loss_table_adam.empty else pd.DataFrame({\"Info\":[\"Ch∆∞a c√≥ d·ªØ li·ªáu\"]}))\n",
        "\n",
        "# ---------------------------- Tab 4: COMPARE ----------------------------\n",
        "with tab4:\n",
        "    st.header(\"So s√°nh L-BFGS vs Adam\")\n",
        "\n",
        "    if \"LBFGS\" in st.session_state.timings:\n",
        "        st.write(f\"‚è±Ô∏è L-BFGS: {st.session_state.timings['LBFGS']:.2f}s\")\n",
        "    if \"Adam\" in st.session_state.timings:\n",
        "        st.write(f\"‚è±Ô∏è Adam: {st.session_state.timings['Adam']:.2f}s\")\n",
        "\n",
        "    if not st.session_state.loss_table.empty:\n",
        "        st.subheader(\"Bi·ªÉu ƒë·ªì ri√™ng Content/Style/Total\")\n",
        "        fig, axs = plt.subplots(3,1, figsize=(6,10))\n",
        "        for idx, loss_name in enumerate([\"Content Loss\",\"Style Loss\",\"Total Loss\"]):\n",
        "            for opt in st.session_state.loss_table[\"Optimizer\"].unique():\n",
        "                df = st.session_state.loss_table[st.session_state.loss_table[\"Optimizer\"]==opt]\n",
        "                axs[idx].plot(df[loss_name].values, label=opt)\n",
        "            axs[idx].set_ylabel(loss_name)\n",
        "            axs[idx].legend()\n",
        "        st.pyplot(fig)\n",
        "    # n√∫t ƒë·ªÉ xem c√¥ng th·ª©c/kh√°i ni·ªám\n",
        "    if st.button(\"üìò Xem kh√°i ni·ªám Adam vs L-BFGS\"):\n",
        "        with st.expander(\"Adam & L-BFGS l√† g√¨? (Kh√°i ni·ªám ƒë∆°n gi·∫£n)\"):\n",
        "            st.markdown(\"\"\"\n",
        "            ## üîµ L-BFGS (Limited-memory BFGS)\n",
        "            - L√† thu·∫≠t to√°n t·ªëi ∆∞u **d·ª±a tr√™n quasi-Newton**, d√πng x·∫•p x·ªâ ƒë·∫°o h√†m b·∫≠c hai (curvature).\n",
        "            - Ra quy·∫øt ƒë·ªãnh b∆∞·ªõc ƒëi t·ªëi ∆∞u **d·ª±a tr√™n h√¨nh d·∫°ng b·ªÅ m·∫∑t loss**, kh√¥ng ch·ªâ d·ª±a tr√™n gradient ƒë∆°n thu·∫ßn.\n",
        "            - Th∆∞·ªùng **h·ªôi t·ª• nhanh** v√† **·ªïn ƒë·ªãnh** trong c√°c b√†i to√°n t·ªëi ∆∞u ·∫£nh (image optimization).\n",
        "            - R·∫•t ph√π h·ª£p v·ªõi **Neural Style Transfer**, theo b√†i b√°o g·ªëc c·ªßa Gatys.\n",
        "\n",
        "            ---\n",
        "\n",
        "            ## üü† Adam (Adaptive Moment Estimation)\n",
        "            - L√† thu·∫≠t to√°n t·ªëi ∆∞u **gradient descent hi·ªán ƒë·∫°i**, c√≥ c∆° ch·∫ø:\n",
        "                - momentum (·ªïn ƒë·ªãnh h∆∞·ªõng ƒëi)\n",
        "                - adaptive learning rate (m·ªói tham s·ªë c√≥ t·ªëc ƒë·ªô ri√™ng)\n",
        "            - R·∫•t m·∫°nh trong **hu·∫•n luy·ªán m√¥ h√¨nh l·ªõn** (deep learning), nh∆∞ng trong NST:\n",
        "                - k·∫øt qu·∫£ ph·ª• thu·ªôc nhi·ªÅu v√†o learning rate\n",
        "                - ƒë√¥i khi k√©m s·∫Øc n√©t h∆°n L-BFGS\n",
        "            - ∆Øu ƒëi·ªÉm: d·ªÖ ƒëi·ªÅu ch·ªânh, linh ho·∫°t, t·ªëc ƒë·ªô m·ªói step nhanh.\n",
        "\n",
        "            \"\"\")\n",
        "\n",
        "        with st.expander(\"So s√°nh nhanh Adam vs L-BFGS\"):\n",
        "            st.markdown(\"\"\"\n",
        "            ## üìä B·∫£ng so s√°nh\n",
        "\n",
        "            | Ti√™u ch√≠ | L-BFGS | Adam |\n",
        "            |---------|--------|------|\n",
        "            | T·ªëc ƒë·ªô h·ªôi t·ª• | ‚≠ê **R·∫•t nhanh** | Trung b√¨nh |\n",
        "            | ƒê·ªô s·∫Øc n√©t (NST) | ‚≠ê **Th∆∞·ªùng cao h∆°n** | C√≥ th·ªÉ m·ªÅm, m∆∞·ª£t h∆°n |\n",
        "            | T√≠nh ·ªïn ƒë·ªãnh | ‚≠ê Cao | Trung b√¨nh |\n",
        "            | D·ªÖ tinh ch·ªânh | √çt (kh√≥ ƒëi·ªÅu ch·ªânh nh∆∞ng m·∫∑c ƒë·ªãnh t·ªët) | ‚≠ê D·ªÖ ƒëi·ªÅu ch·ªânh (LR) |\n",
        "            | Ph√π h·ª£p cho NST | ‚≠ê‚≠ê **R·∫•t ph√π h·ª£p** | H·ª£p nh∆∞ng kh√¥ng t·ªëi ∆∞u |\n",
        "            | Ph√π h·ª£p DL n√≥i chung | Kh√¥ng | ‚≠ê‚≠ê **R·∫•t ph√π h·ª£p** |\n",
        "            | Ph·ª• thu·ªôc LR | Kh√¥ng | ‚≠ê C√≥ |\n",
        "\n",
        "            \"\"\")\n",
        "\n",
        "        with st.expander(\"K·∫øt lu·∫≠n ‚Äî thu·∫≠t to√°n n√†o t·ªëi ∆∞u h∆°n cho NST?\"):\n",
        "            st.markdown(\"\"\"\n",
        "            ## üèÜ K·∫øt lu·∫≠n\n",
        "\n",
        "            - **L-BFGS th∆∞·ªùng cho k·∫øt qu·∫£ t·ªët h∆°n trong Neural Style Transfer**:\n",
        "                - ·∫£nh s·∫Øc n√©t h∆°n\n",
        "                - h·ªôi t·ª• nhanh h∆°n\n",
        "                - √≠t ph·ª• thu·ªôc hyperparameter\n",
        "                - ƒë∆∞·ª£c d√πng trong b√†i b√°o g·ªëc\n",
        "\n",
        "            - **Adam**:\n",
        "                - t·ªët trong hu·∫•n luy·ªán m√¥ h√¨nh l·ªõn\n",
        "                - nh∆∞ng trong NST, c·∫ßn ƒëi·ªÅu ch·ªânh LR k·ªπ n·∫øu kh√¥ng ·∫£nh c√≥ th·ªÉ b·ªã m·ªù ho·∫∑c nhi·ªÖu\n",
        "\n",
        "            üëâ **N·∫øu m·ª•c ti√™u c·ªßa b·∫°n l√† ch·∫•t l∆∞·ª£ng ·∫£nh NST cao ‚Üí d√πng L-BFGS.**\n",
        "            üëâ **N·∫øu mu·ªën t√πy ch·ªânh linh ho·∫°t ho·∫∑c mu·ªën th·ª≠ nhi·ªÅu bi·∫øn th·ªÉ ‚Üí Adam l√† l·ª±a ch·ªçn ti·ªán h∆°n.**\n",
        "            \"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit ngrok pyngrok"
      ],
      "metadata": {
        "id": "dgOjh0BYI427"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 33XzMWuEzakeuxnB6brJBWUnXNB_3vqJtZVihToGSoY33VJZM"
      ],
      "metadata": {
        "id": "sGzY_xJAI98A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Kill tunnel c≈©\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# 2Ô∏è‚É£ Ch·∫°y Streamlit background (port 8502)\n",
        "!nohup streamlit run app.py --server.port 8501 > streamlit.log 2>&1 &\n",
        "\n",
        "# 3Ô∏è‚É£ Ch·ªù Streamlit kh·ªüi ƒë·ªông (5-10s)\n",
        "import time\n",
        "time.sleep(8)\n",
        "\n",
        "# 4Ô∏è‚É£ M·ªü ngrok cho port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "id": "equx-rjTJBdB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}