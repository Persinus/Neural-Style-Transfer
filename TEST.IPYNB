import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image, UnidentifiedImageError
import matplotlib.pyplot as plt
import requests
from io import BytesIO

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Load image and preprocess, với kiểm tra lỗi
def load_image_from_url(url, max_size=512, shape=None):
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    except Exception as e:
        print(f"Error requesting URL: {url}\n{e}")
        raise

    if response.status_code != 200:
        raise Exception(f"Failed to download image. Status code: {response.status_code} for URL: {url}")

    try:
        image = Image.open(BytesIO(response.content)).convert("RGB")
    except UnidentifiedImageError as e:
        print(f"UnidentifiedImageError: Cannot open image from URL: {url}")
        raise

    # Resize / thumbnail
    if shape:
        # shape is (H, W) tuple; PIL expects (width, height)
        w = shape[1]
        h = shape[0]
        image = image.resize((w, h), Image.LANCZOS)
    else:
        size = max(image.size)
        if size > max_size:
            size = max_size
        image.thumbnail((size, size), Image.LANCZOS)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    image = transform(image).unsqueeze(0)
    return image.to(device)

# Convert tensor to PIL Image for display
def im_convert(tensor):
    image = tensor.clone().detach().cpu().squeeze(0)
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    image = image * std + mean
    image = torch.clamp(image, 0, 1)
    return transforms.ToPILImage()(image)

# Gram matrix calculation
def gram_matrix(tensor):
    b, c, h, w = tensor.size()
    tensor = tensor.view(b, c, h * w)
    gram = torch.bmm(tensor, tensor.transpose(1, 2))
    return gram / (c * h * w)

# VGG feature extractor for content and style
class VGGFeatures(nn.Module):
    def __init__(self, content_layers, style_layers):
        super(VGGFeatures, self).__init__()
        self.vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features.eval()
        for param in self.vgg.parameters():
            param.requires_grad = False
        self.content_layers = content_layers
        self.style_layers = style_layers

    def forward(self, x):
        content_features = {}
        style_features = {}
        for name, layer in self.vgg._modules.items():
            x = layer(x)
            if name in self.content_layers:
                content_features[name] = x
            if name in self.style_layers:
                style_features[name] = x
        return content_features, style_features

# URLs for content and style images
content_url = "https://hnm.1cdn.vn/2023/01/17/hanoimoi.com.vn-uploads-images-tuandiep-2023-01-17-_meo_vang3.jpg"
style_url   = "https://vietartview.com.vn/wp-content/uploads/2023/02/C-5.png"

# Load content image
print("Loading content image from:", content_url)
content = None
try:
    content = load_image_from_url(content_url, max_size=256)
    print("✅ Content image loaded successfully.")
except Exception as e:
    print("❌ Failed to load content image.")
    raise

# Load style image (resize to content size)
style = None
try:
    style = load_image_from_url(style_url, shape=tuple(content.shape[-2:]))
    print("✅ Style image loaded successfully.")
except Exception as e:
    print("❌ Failed to load style image.")
    raise

# Show input images
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.imshow(im_convert(content))
plt.title("Content Image")
plt.axis("off")
plt.subplot(1,2,2)
plt.imshow(im_convert(style))
plt.title("Style Image")
plt.axis("off")
plt.show()

# Initialize target image as copy of content image
target = content.clone().requires_grad_(True).to(device)

# Define VGG layers to extract features
content_layers = ["21"]  # conv4_2
style_layers = ["0", "5", "10", "19", "28"]  # conv1_1, conv2_1, conv3_1, conv4_1, conv5_1

# Extract features from content and style images
extractor = VGGFeatures(content_layers, style_layers).to(device)
content_features, _ = extractor(content)
_, style_features = extractor(style)
style_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}

# Loss weights
alpha = 1          # Content weight
beta = 1e4         # Style weight (có thể điều chỉnh)

# Optimizer
optimizer = optim.LBFGS([target])

# Training loop
steps = 500
run = [0]

while run[0] <= steps:
    def closure():
        optimizer.zero_grad()
        target_content, target_style = extractor(target)

        # Content loss
        c_loss = 0
        for l in content_layers:
            c_loss += torch.mean((target_content[l] - content_features[l])**2)

        # Style loss
        s_loss = 0
        for l in style_layers:
            target_g = gram_matrix(target_style[l])
            s_loss_layer = torch.mean((target_g - style_grams[l])**2)
            s_loss += s_loss_layer

        loss = alpha * c_loss + beta * s_loss
        loss.backward()

        # Print losses every 100 steps
        if run[0] % 100 == 0:
            print(f"Step {run[0]} | Total Loss: {loss.item():.6f} | Content Loss: {c_loss.item():.6f} | Style Loss: {s_loss.item():.6f}")
            for l in style_layers:
                mean_feat = target_style[l].mean().item()
                print(f"    Style feature mean layer {l}: {mean_feat:.6f}")
            img = im_convert(target)
            plt.imshow(img)
            plt.axis("off")
            plt.title(f"Output Step {run[0]}")
            plt.show()

        run[0] += 1
        return loss

    optimizer.step(closure)

# Show final output image
final_img = im_convert(target)
plt.imshow(final_img)
plt.axis("off")
plt.title("Final NST Output")
plt.show()
